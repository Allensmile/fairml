========

FairML: Auditing Black-Box Predictive Algorithms
=====================
Welcome to FairML! FairML is a collection of tools for auditing the data mining/machine learning process including algorithms, and input for bias. 

<img src="https://raw.githubusercontent.com/adebayoj/FairML/master/logo2.png" width="700">

This repo contains the source code used as part of FairML




### Abstract (Tentative)

We present FairML, a system developed to study
bias and enable interpretability of black-box predictive
models. FairML consists of two major
components: the first component analyzes input
training data in order to characterize the level of
bias encoded in the dataset, and the second component
consists of a variable ranking methodology
that seeks to quantify a black-boxâ€™s dependence
on its inputs. FairML outputs a report explaining
its results in natural language for analysts.
We show through simulation that when we
have access to the black-box algorithm for repeated
querying, our orthogonalization algorithm
outperforms other ranking methods from literature.
In high stakes contexts such as determination
of access to credit, employment, and insurance
where discrimination based on sensitive attributes
such as race, gender, and sexual orientation
is prohibited by law, FairML provides a way
for analysts at government institutions to quickly
perform audits of black-box algorithms and corresponding
input data.

Feel free to email the authors with any questions:  
[Julius Adebayo](https://github.com/adebayoj) (juliusad@mit.edu)   


### Data used in the paper

Include Sample data here. 


