========

FairML: Auditing Black-Box Predictive Models
=====================
Welcome to FairML! FairML is a collection of tools for auditing the data mining/machine learning process including algorithms, and input for bias. 

<img src="https://raw.githubusercontent.com/adebayoj/FairML/master/doc/images/logo2.png" width="700">

This repo contains the source code used as part of FairML


### Abstract (Tentative)

Predictive models are increasingly deployed for the purpose of determining access to
services such as credit, insurance, and employment. Despite societal gains in efficiency
and productivity through deployment of these models, potential systemic flaws have
not been fully addressed, particularly the potential for unintentional discrimination.
This discrimination could be on the basis of race, gender, religion, sexual orientation,
or other characteristics. This thesis addresses the question: how can an analyst
determine the relative significance of the inputs to a black-box predictive model in order
to assess the model’s fairness (or discriminatory extent)? We present FairML, an endto-
end toolbox for auditing predictive models by quantifying the relative significance
of the model’s inputs. FairML leverages model compression and four input ranking
algorithms to quantify a model’s relative predictive dependence on its inputs. The
relative significance of the inputs to a predictive model can then be used to assess
the fairness (or discriminatory extent) of such a model. With FairML, analysts can
more easily audit cumbersome predictive models that are difficult to interpret.s of black-box algorithms and corresponding
input data.

### Motivation

<img src="https://raw.githubusercontent.com/adebayoj/FairML/master/doc/images/fairml_architecture.png" width="700">

### Example Output

<img src="https://raw.githubusercontent.com/adebayoj/FairML/master/doc/images/ricci_analysis.png" width="700">


Feel free to email the authors with any questions:  
[Julius Adebayo](https://github.com/adebayoj) (juliusad@mit.edu)   


### Data used in the paper

Include Sample data here. 


